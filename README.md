#Numerical Methods And Analysis

In my recent work on numerical methods, I focused extensively on implementing and analyzing various techniques crucial for solving mathematical problems in computational settings. This included rigorous error analysis, particularly concerning truncation and rounding effects, which are inherent in floating-point arithmetic. I successfully implemented Gaussian elimination and both Crout and Doolittle variants of LU decomposition for efficient matrix solving. Additionally, I developed and evaluated iterative methods such as Gauss-Seidel, Gauss-Jacobi, and Successive Over-Relaxation (SOR) to approximate solutions to linear equations, considering their convergence properties and computational efficiency. Root-finding techniques like Regula-Falsi, Newton-Raphson, Secant, and fixed-point iteration were also implemented and assessed for accuracy and convergence rates. Furthermore, I explored polynomial interpolation methods including Hermite, linear spline, and cubic spline techniques, applying them to accurately approximate functions from discrete data points. Lastly, I employed numerical integration methods such as Trapezoidal and Simpsonâ€™s rules to compute definite integrals of functions, considering both accuracy and computational efficiency in various scenarios. Through these implementations and analyses, I gained valuable insights into the strengths and limitations of each method, ensuring robust solutions to diverse mathematical problems encountered in scientific and engineering applications.
